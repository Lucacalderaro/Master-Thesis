\chapter{Introduction}
Since the creation of the first electronic digital computing device, physicists have used computers as a valuable tool for their research. The study and implementation of numerical methods to solve physical problems led to the growth of a new field of physics called computational physics. It is not surprising that this field of study has branches in every major field in physics: from computational mechanics to computational astrophysics, from computational condensed matter to computational particle physics. Mathematical models, developed to accurately describe natural phenomena, are often difficult to solve analytically. Typically, the construction of a physics model begins with the definition of the energy of the system, which contains the interactions between the components of the system and the kinetic energy of the particles -- when these are allowed to move. This in turn leads to the action of the system and the equations of motion by means of the least action principle~\citep{LL85}. At this stage, depending on what system is under study, many features can be already found without considering the equations of motion. For instance, the phase transitions of a spin system in the canonical ensemble may be studied considering the partition function which in turn lets us calculate observables, like the magnetization as a function of the temperature and the external magnetic field~\citep{Huang28}. These features regard the equilibrium properties of the system and may constitute a rather challenging analytical problem. Even more challenging is the study of the dynamical properties, in which one has to deal with the equations of motion. In particular, one would have to solve the Cauchy problem, in which the initial state of the system is given along with the equations.

The correctness of a physics model is evaluated comparing its results with the outcomes of the experiment. As we said, it is not always possible to get the results we need from the model by mean of an analytical method. A possible approach to tackle these problems is to use algorithms to numerically solve the equations.

Complicated systems lead to numerically intense simulations that require a great amount of computational resources. For this reason, the development of efficient code, which is able to take advantage of the computational resources available nowadays, is of fundamental importance. The lack of efficiency leads to long execution time that can extend to months or even years, making the simulations impracticable. 

The most powerful computational facilities at our disposal are supercomputers. These machines consist of many single processing units connected with each other to share data. An algorithm can get the most out of these machines when it is able to use many processing units at the same time, parallelizing the tasks to be performed. Processing units can be distinguished into two main categories: central processing units (CPUs) and graphics processing units (GPUs). The former type dedicates most of their transistor count to improve sequential code performance, while the latter type takes a different approach, housing hundreds of simple execution units which run parallel code. Due to their advantageous features, GPUs are gaining popularity in the computational physics field. They are designed to perform simple calculations on large amount of data in parallel. This can lead to a great reduction of the execution time with respect to a sequential or parallel implementation on a CPU.

%In this work we developed a solver for Schr\"odinger equation that scales to	massively parallel computing clusters. Our point of departure was the recent work of Wittek and Cucchietti~\citep{Wittek20131165}, in which they extended the single-node parallel kernels in Ref.~\citep{bederian2011boosting} to use distributed resources. We further extended the code implementing the external potential in the Hamiltonian. This allows to simulate a wider range of problems in quantum physics. The implementation is also able to solve the nonlinear Schr\"odinger equation, in which the nonlinear term is given by the delta-function interactions between bosonic particles. The code implements cache optimized kernels for both CPUs and GPUs, making it versatile to use on different types of computing resources. These kernels are based on the second order Trotter--Suzuki decomposition~\citep{Suzuki1992387}. The approximation allows the evolution operator to be decomposed in a sequence of operators easy to evaluate.

In this work we developed a solver for Schr\"odinger equation that scales to	massively parallel computing clusters. Our point of departure was the recent work of Wittek and Cucchietti~\citep{Wittek20131165}. In their work, they extended the single-node parallel kernels in Ref.~\citep{bederian2011boosting} to use distributed resources. These kernels are cache optimized kernels for both CPUs and GPUs based on the second order Trotter--Suzuki decomposition~\citep{Suzuki1992387}, and implement a solver for the Schr\"odinger equation of a free particle. 

We extended the code implementing the following features:
\begin{itemize}
\item The Hamiltonian includes the stationary external potential. The implementation is also able to solve the nonlinear Schr\"odinger equation, in which the nonlinear term is given by the delta-function interactions between bosonic particles -- this is implemented in the CPU kernel.

\item Imaginary time evolution to approximate the ground state.

\item Command-line interface and application programming interface for flexible use.

\item Python and MATLAB wrappers are provided.
\end{itemize}
The new version of the program has been already published and appears in a short paper\footnote{Wittek, P. and Calderaro, L., Extended computational kernels in a massively parallel implementation of the Trotter--Suzuki approximation, Computer Physics Communications, August 2015.}. 

As an application of the extended implementation, we have been able to simulate the evolution of an interacting Bose-Einstein condensate described by the Gross-Pitaevskii equation. The simulation reproduced the experimental results in Ref.~\citep{DSF00}.

The content of the Thesis is organized in the following way. The second chapter introduces to the Trotter--Suzuki approximation. In the third we explicitly calculate the evolution operator that is implemented in our code. The fourth chapter gives the details of the algorithms used in our code, describing the optimization techniques. The fifth chapter presents the application to the interacting BEC and we compare our results with the experimental study of Ref.~\citep{DSF00}. We conclude summarizing our achievements and outlining the future directions of research.