\chapter{Introduction}
Since the creation of the first electronic digital computing device\footnote{John Vincent Atanasoff and Clifford Berry created the first electronic non-programmable, digital computing device, the Atanasoffâ€“Berry Computer, from 1937 to 1942}, physicists have used computers as a valuable tools for their research. The study and the implementation of numerical methods to solve physical problem led to the growth of a new field of physics called computational physics. It is not surprising that this field of physics has branches in every major field in physics: from computational mechanics to computational astrophysics, from computational condensed matter to computational particle physics.
%put some references?
 Mathematical models, developed to accurately describe natural phenomena, are very often difficult to solve analytically. The usual approach to create them is to define the energy of the system, which contains the interactions between the components of the system and the kinetic of the particles -- when these are allowed to move --. This in turn leads to the action of the system and the equations of motion by means of the least action principle~\citep{LL85}. At this stage, depending on what system is under study, many features can be already found without considering the equations of motion. For instance, the phase transitions of a spin system in the canonical ensemble may be studied considering the partition function which in turn let us calculate observables, like the magnetization as a function of the temperature and the external magnetic field~\citep{Huang28}. These features regards the equilibrium properties of the system and may constitute a rather challenging analytical problem. Even more challenging may be the study of the dynamical properties, in which one has to deal with the equations of motion. In particular, one would have to solve the Cauchy problem, in which the initial state of the system is given along with the equations.

The correctness of a physics model is evaluated comparing its results with the outcomes of the experiment. As we said, it is not always possible to get the results we need from the model by mean of analytical method. A possible approach to tackle these problems is to use algorithm to numerically solve the equations.

Complicated systems lead to numerically intense simulations that require a great amount of computational resources. For this reason, the development of efficient code, able to take advantage of the computational resources available nowadays, is of fundamental importance. A lack in efficiency may lead to long time of execution, that can extend to months or even years, making the simulations impracticable. 

The most powerful computational facilities at our disposal are supercomputers. These machines consist of many single processing units connected with each other to share data. An algorithm can get the most from these machines when it is able to use many processing units at the same time, parallelizing the tasks to be performed. Processing units can be distinguished into two main categories: central processing units (CPUs) and graphic processing units (GPUs). The former dedicate most of their transistor count to improve sequential code performance, while the latter take a different approach housing hundreds of simple execution units which run parallel code. Due to their features, GPUs are gaining popularity in the computational physics field. They are designed to perform simple calculations on large amount of data in parallel. These features can lead to a great speed-up of the execution time with respect to a sequential code implemented on a CPU.

In this work we developed a solver for schr\"odinger equation that scales to	massively parallel computing clusters. We started from the recent work of Wittek and Cucchietti~\citep{Wittek20131165}, in which they extended the single-node parallel kernels in Ref.~\citep{bederian2011boosting} to use distributed resources. We further extended the code implementing the external potential in the Hamiltonian. This allows to simulate a wider range of problems in quantum physics. The implementation is also able to solve the nonlinear Schr\"odinger equation. The code implements cache optimized kernels for both CPUs and GPUs, making it versatile to use on different types of computing resources. These kernels are based on the second order Trotter-Suzuki decomposition~\citep{Suzuki1992387}. The approximation allows the evolution operator to be decomposed in a sequence of operators easy to evaluate.

As application of the code we were able to simulate the evolution of an interacting Bose-Einstein condensate, described by the Gross-Pitaevskii equation. The simulation reproduced the experimental results in Ref.~\citep{DSF00}.

The content of the Thesis is organized in the following way. The second chapter introduces to the Trotter-Suzuki approximation. In the third we explicitly calculate the evolution operator that is implemented in our code. The fourth chapter gives the details of the algorithms used in our code, describing the optimization techniques. The fifth chapter presents the application to the interacting BEC and we compare our results with the experimental study of Ref.~\citep{DSF00}. We conclude summarizing our achievements and outlining the future directions of research.